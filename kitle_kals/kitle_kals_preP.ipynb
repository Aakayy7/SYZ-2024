{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass&Calsification detction & converting images from dicom 2 png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Apply windowing to enhance image contrast based on Window Center (WC) and Window Width (WW)\n",
    "def apply_windowing(img_data, wc, ww):\n",
    "    try:\n",
    "        # Calculate minimum and maximum intensity values based on windowing\n",
    "        min_val, max_val = wc - ww // 2, wc + ww // 2\n",
    "        # Clip pixel values between min and max and normalize to a range of 0-255\n",
    "        img_data = np.clip(img_data, min_val, max_val)\n",
    "        # Return the windowed image data as 8-bit unsigned integer values\n",
    "        return ((img_data - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "    except Exception as e:\n",
    "        # Print error message if windowing fails\n",
    "        print(f\"Error in apply_windowing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert a DICOM file to a PNG file\n",
    "def convert_dicom_to_png(input_file, output_file):\n",
    "    try:\n",
    "        # Read DICOM file\n",
    "        ds = pydicom.dcmread(input_file)\n",
    "        # Extract pixel data from the DICOM file\n",
    "        img_data = ds.pixel_array\n",
    "        # Get the Window Center (WC) and Window Width (WW) from DICOM metadata\n",
    "        wc = ds.get(\"WindowCenter\", img_data.mean())\n",
    "        ww = ds.get(\"WindowWidth\", img_data.max() - img_data.min())\n",
    "        # Apply windowing to the image\n",
    "        img_data = apply_windowing(img_data, wc if isinstance(wc, (int, float)) else wc[0], ww if isinstance(ww, (int, float)) else ww[0])\n",
    "        # If windowing was successful, save the image as a PNG\n",
    "        if img_data is not None:\n",
    "            image = Image.fromarray(img_data)  # Convert to PIL Image object\n",
    "            image.save(output_file)  # Save as PNG\n",
    "    except Exception as e:\n",
    "        # Print error message if DICOM to PNG conversion fails\n",
    "        print(f\"Error converting DICOM to PNG: {e}\")\n",
    "\n",
    "# Check if the image is light (average pixel value > 128)\n",
    "def is_image_light(image_path):\n",
    "    try:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        # Convert the image to grayscale\n",
    "        image_gray = ImageOps.grayscale(image)\n",
    "        # Convert the grayscale image to a NumPy array\n",
    "        image_array = np.array(image_gray)\n",
    "        # Calculate the average pixel value of the grayscale image\n",
    "        avg_pixel_value = np.mean(image_array)\n",
    "        # Return True if the average pixel value is greater than 128, indicating a light image\n",
    "        return avg_pixel_value > 128\n",
    "    except Exception as e:\n",
    "        # Print error message if the lightness check fails\n",
    "        print(f\"Error in checking image lightness: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process an image: convert DICOM to PNG, invert if light, and delete the DICOM file\n",
    "def process_image(dicom_path, png_path):\n",
    "    try:\n",
    "        # Convert DICOM file to PNG\n",
    "        convert_dicom_to_png(dicom_path, png_path)\n",
    "        # If the PNG file exists and the image is light, invert the colors\n",
    "        if os.path.exists(png_path) and is_image_light(png_path):\n",
    "            image = Image.open(png_path)  # Open the PNG image\n",
    "            image_inverted = ImageOps.invert(image.convert('RGB'))  # Invert the image\n",
    "            image_inverted.save(png_path)  # Save the inverted image\n",
    "        # Remove the original DICOM file after processing\n",
    "        os.remove(dicom_path)\n",
    "    except Exception as e:\n",
    "        # Print error message if image processing fails\n",
    "        print(f\"Error processing image {dicom_path}: {e}\")\n",
    "\n",
    "# Process all DICOM images in a folder\n",
    "def process_images_in_folder(folder_path):\n",
    "    # Use ThreadPoolExecutor to process images in parallel with 4 threads\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:  # Adjust the number of workers as needed\n",
    "        futures = []  # List to store future tasks\n",
    "        # Iterate through each subfolder in the specified folder\n",
    "        for subfolder in tqdm(os.listdir(folder_path)):\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)  # Full path of the subfolder\n",
    "            if os.path.isdir(subfolder_path):  # Check if it's a directory\n",
    "                # Iterate through each file in the subfolder\n",
    "                for file_name in os.listdir(subfolder_path):\n",
    "                    # Process only DICOM files (.dcm)\n",
    "                    if file_name.lower().endswith('.dcm'):\n",
    "                        dicom_path = os.path.join(subfolder_path, file_name)  # Full path of the DICOM file\n",
    "                        png_path = os.path.join(subfolder_path, file_name.replace('.dcm', '.png'))  # Path for the PNG file\n",
    "                        # Submit the process_image task to the thread pool\n",
    "                        futures.append(executor.submit(process_image, dicom_path, png_path))\n",
    "        # Wait for all the tasks to complete\n",
    "        for future in tqdm(futures):\n",
    "            try:\n",
    "                future.result()  # Retrieve the result of each task\n",
    "            except Exception as e:\n",
    "                # Print error message if any task fails\n",
    "                print(f\"Error in processing a future: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the folder containing the DICOM files\n",
    "    folder_path = r\"C:\\Users\\zafer\\Desktop\\competition_dataset\\competition_dataset\"\n",
    "    # Process the DICOM files in the folder\n",
    "    process_images_in_folder(folder_path)\n",
    "    # Print a message once processing is complete\n",
    "    print(\"Image processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to predict labels for a given frame using the model\n",
    "def Predict_frame(frame, model):\n",
    "    \"\"\"\n",
    "    Predict bounding boxes and class labels for a given frame.\n",
    "    \n",
    "    Parameters:\n",
    "    - frame: The input image/frame.\n",
    "    - model: The YOLO model used for prediction.\n",
    "    \n",
    "    Returns:\n",
    "    - A list of predicted labels [class, probability, x_center, y_center, width, height] for each detection.\n",
    "    \"\"\"\n",
    "    predictions = model(frame, save_txt=None)  # Get predictions from the model without saving to a file\n",
    "    labels = []  # Initialize an empty list to store labels\n",
    "    for idx, prediction in enumerate(predictions[0].boxes.xywhn):  # xywhn is the normalized bounding box\n",
    "        cls = int(predictions[0].boxes.cls[idx].item())  # Get the class of the detected object\n",
    "        prob = predictions[0].boxes.conf[idx].item()  # Get the confidence score of the prediction\n",
    "        # Format the prediction into a string: class, probability, x_center, y_center, width, height\n",
    "        line = f\"{cls} {prob} {prediction[0].item()} {prediction[1].item()} {prediction[2].item()} {prediction[3].item()}\"\n",
    "        numbers = list(map(float, line.split()))  # Convert the string to a list of floats\n",
    "        labels.append(numbers)  # Append the label to the list\n",
    "    return labels  # Return the list of labels\n",
    "\n",
    "# Function to unnormalize YOLO format coordinates into pixel-based coordinates\n",
    "def unnormalize_Yolo_cords(label, image):\n",
    "    \"\"\"\n",
    "    Convert YOLO format bounding box coordinates into pixel-based coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - label: YOLO format [class, probability, x_center, y_center, width, height].\n",
    "    - image: The image/frame to get dimensions from.\n",
    "\n",
    "    Returns:\n",
    "    - The class, probability, and pixel-based bounding box coordinates [x1, y1, x2, y2].\n",
    "    \"\"\"\n",
    "    img_height, img_width, _ = image.shape  # Get image dimensions\n",
    "    \n",
    "    cls, prob, x_center, y_center, width_bbox, height_bbox = label\n",
    "    x = x_center * img_width\n",
    "    y = y_center * img_height\n",
    "    bbox_width = width_bbox * img_width\n",
    "    bbox_height = height_bbox * img_height\n",
    "\n",
    "    # Calculate pixel-based coordinates\n",
    "    x1 = int(x - bbox_width / 2)\n",
    "    x2 = int(x + bbox_width / 2)\n",
    "    y1 = int(y - bbox_height / 2)\n",
    "    y2 = int(y + bbox_height / 2)\n",
    "\n",
    "    return cls, prob, x1, y1, x2, y2\n",
    "\n",
    "# Function to reverse the transformation and retrieve original label coordinates\n",
    "def reverse_label_conf(x1, y1, x2, y2, image):\n",
    "    \"\"\"\n",
    "    Reverse the transformation to get the original label coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    - x1, y1, x2, y2: Transformed bounding box coordinates.\n",
    "    - image: The image to derive the width and height from.\n",
    "    \n",
    "    Returns:\n",
    "    - Original coordinates as a formatted string: \"x1,y1;x1,y2;x2,y2;x2,y1\".\n",
    "    \"\"\"\n",
    "    # Convert image to RGB format (if necessary)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    height, width, _ = image_rgb.shape\n",
    "\n",
    "    half_width = width / 2\n",
    "    half_height = height / 2\n",
    "    \n",
    "    # Reverse transformation\n",
    "    x1_orig = round(x1 - half_width, 4)\n",
    "    y1_orig = round(y1 - half_height, 5)\n",
    "    x2_orig = round(x2 - half_width, 4)\n",
    "    y2_orig = round(y2 - half_height, 5)\n",
    "    \n",
    "    # Format into a string\n",
    "    coord_str = f\"{x1_orig},{y1_orig};{x1_orig},{y2_orig};{x2_orig},{y2_orig};{x2_orig},{y1_orig}\"\n",
    "    \n",
    "    return coord_str\n",
    "\n",
    "# Example usage for testing:\n",
    "# transformed_coords = (480, 1085, 742, 1380)  # Sample transformed coordinates\n",
    "# original_labels = reverse_label_conf(*transformed_coords, image)  # Get original coordinates\n",
    "# print(original_labels)  # Print the original label coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving the image to the model and testing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing your images\n",
    "image_dir = r'C:\\Users\\zafer\\Desktop\\KIitlekals_competition_dataset - Kopya\\competition_dataset'  # Change this to your image directory\n",
    "\n",
    "# Lists to store DataFrame rows\n",
    "all_data = []\n",
    "\n",
    "# Iterate through all image files in the directory\n",
    "for image_file in os.listdir(image_dir):\n",
    "    if image_file.lower().endswith(('.jpg', '.jpeg', '.png')):  # Process only image files\n",
    "        # Construct the full image path\n",
    "        image_path = os.path.join(image_dir, image_file)\n",
    "        \n",
    "        # Read and preprocess the image\n",
    "        image_with_orginal_size = cv2.imread(image_path)  # Read the image with its original size\n",
    "        imagefor_predict = cv2.resize(image_with_orginal_size, (1024, 1024))  # Resize image for model prediction\n",
    "        \n",
    "        # Predict the labels using the trained model\n",
    "        labels = Predict_frame(frame=imagefor_predict, model=kitle_kalsifikasyon)  # Prediction function\n",
    "        \n",
    "        # Initialize lists for storing results\n",
    "        kitle = []  # List for storing mass (kitle) bounding boxes\n",
    "        kalsifikasyon = []  # List for storing calcification bounding boxes\n",
    "        kitle_guven = []  # List for storing mass confidence scores\n",
    "        kalsifikasyon_guven = []  # List for storing calcification confidence scores\n",
    "        \n",
    "        # Process each label returned by the model\n",
    "        for i in range(len(labels)):\n",
    "            print(i)  # Print the index to track the loop progress\n",
    "            # Get the bounding box coordinates and other details in pixel format\n",
    "            cls, prob, x1, y1, x2, y2 = unnormalize_Yolo_cords(label=labels[i], image=image_with_orginal_size)\n",
    "            \n",
    "            # Convert transformed coordinates back to original format\n",
    "            transformed_coords = (x1, y1, x2, y2)\n",
    "            original_labels = reverse_label_conf(*transformed_coords, image=image_with_orginal_size)  # Reverse transformation\n",
    "            \n",
    "            # Append labels and confidence based on class (0 for mass, 1 for calcification)\n",
    "            if cls == 0:\n",
    "                kitle.append([original_labels])  # Append mass bounding box\n",
    "                kitle_guven.append([prob])  # Append mass confidence score\n",
    "            else:\n",
    "                kalsifikasyon.append([original_labels])  # Append calcification bounding box\n",
    "                kalsifikasyon_guven.append([prob])  # Append calcification confidence score\n",
    "            \n",
    "            print(original_labels)  # Print the original labels for debugging\n",
    "        \n",
    "        # Ensure all lists are structured as list of lists\n",
    "        kitle = kitle if kitle else []  # Ensure 'kitle' is not empty\n",
    "        kitle_guven = kitle_guven if kitle_guven else []  # Ensure 'kitle_guven' is not empty\n",
    "        kalsifikasyon = kalsifikasyon if kalsifikasyon else [[]]  # If empty, assign a placeholder\n",
    "        kalsifikasyon_guven = kalsifikasyon_guven if kalsifikasyon_guven else [[]]  # Same for confidence scores\n",
    "        \n",
    "        # Create a dictionary for the current image\n",
    "        image_data = {\n",
    "            'filename': image_file,  # Store the filename of the image\n",
    "            'kitle': kitle,  # Store mass bounding boxes\n",
    "            'kitle_guven': kitle_guven,  # Store mass confidence scores\n",
    "            'kalsifikasyon': kalsifikasyon,  # Store calcification bounding boxes\n",
    "            'kalsifikasyon_guven': kalsifikasyon_guven  # Store calcification confidence scores\n",
    "        }\n",
    "        \n",
    "        # Append the current image data to the list\n",
    "        all_data.append(image_data)  # Add this image's data to the global list\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(all_data)  # Convert the list of dictionaries to a pandas DataFrame\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(r'C:\\Users\\zafer\\Desktop\\kitle_kals_image_data.xlsx', index=False)  # Save DataFrame to Excel\n",
    "\n",
    "print(\"DataFrame successfully saved to image_data.xlsx\")  # Print confirmation message\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
