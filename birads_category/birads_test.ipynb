{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# birads_preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Apply windowing to enhance image contrast based on Window Center (WC) and Window Width (WW)\n",
    "def apply_windowing(img_data, wc, ww):\n",
    "    try:\n",
    "        # Calculate minimum and maximum intensity values based on windowing\n",
    "        min_val, max_val = wc - ww // 2, wc + ww // 2\n",
    "        # Clip pixel values between min and max and normalize to a range of 0-255\n",
    "        img_data = np.clip(img_data, min_val, max_val)\n",
    "        # Return the windowed image data as 8-bit unsigned integer values\n",
    "        return ((img_data - min_val) / (max_val - min_val) * 255).astype(np.uint8)\n",
    "    except Exception as e:\n",
    "        # Print error message if windowing fails\n",
    "        print(f\"Error in apply_windowing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Convert a DICOM file to a PNG file\n",
    "def convert_dicom_to_png(input_file, output_file):\n",
    "    try:\n",
    "        # Read DICOM file\n",
    "        ds = pydicom.dcmread(input_file)\n",
    "        # Extract pixel data from the DICOM file\n",
    "        img_data = ds.pixel_array\n",
    "        # Get the Window Center (WC) and Window Width (WW) from DICOM metadata\n",
    "        wc = ds.get(\"WindowCenter\", img_data.mean())\n",
    "        ww = ds.get(\"WindowWidth\", img_data.max() - img_data.min())\n",
    "        # Apply windowing to the image\n",
    "        img_data = apply_windowing(img_data, wc if isinstance(wc, (int, float)) else wc[0], ww if isinstance(ww, (int, float)) else ww[0])\n",
    "        # If windowing was successful, save the image as a PNG\n",
    "        if img_data is not None:\n",
    "            image = Image.fromarray(img_data)  # Convert to PIL Image object\n",
    "            image.save(output_file)  # Save as PNG\n",
    "    except Exception as e:\n",
    "        # Print error message if DICOM to PNG conversion fails\n",
    "        print(f\"Error converting DICOM to PNG: {e}\")\n",
    "\n",
    "# Check if the image is light (average pixel value > 128)\n",
    "def is_image_light(image_path):\n",
    "    try:\n",
    "        # Open the image file\n",
    "        image = Image.open(image_path)\n",
    "        # Convert the image to grayscale\n",
    "        image_gray = ImageOps.grayscale(image)\n",
    "        # Convert the grayscale image to a NumPy array\n",
    "        image_array = np.array(image_gray)\n",
    "        # Calculate the average pixel value of the grayscale image\n",
    "        avg_pixel_value = np.mean(image_array)\n",
    "        # Return True if the average pixel value is greater than 128, indicating a light image\n",
    "        return avg_pixel_value > 128\n",
    "    except Exception as e:\n",
    "        # Print error message if the lightness check fails\n",
    "        print(f\"Error in checking image lightness: {e}\")\n",
    "        return False\n",
    "\n",
    "# Process an image: convert DICOM to PNG, invert if light, and delete the DICOM file\n",
    "def process_image(dicom_path, png_path):\n",
    "    try:\n",
    "        # Convert DICOM file to PNG\n",
    "        convert_dicom_to_png(dicom_path, png_path)\n",
    "        # If the PNG file exists and the image is light, invert the colors\n",
    "        if os.path.exists(png_path) and is_image_light(png_path):\n",
    "            image = Image.open(png_path)  # Open the PNG image\n",
    "            image_inverted = ImageOps.invert(image.convert('RGB'))  # Invert the image\n",
    "            image_inverted.save(png_path)  # Save the inverted image\n",
    "        # Remove the original DICOM file after processing\n",
    "        os.remove(dicom_path)\n",
    "    except Exception as e:\n",
    "        # Print error message if image processing fails\n",
    "        print(f\"Error processing image {dicom_path}: {e}\")\n",
    "\n",
    "# Process all DICOM images in a folder\n",
    "def process_images_in_folder(folder_path):\n",
    "    # Use ThreadPoolExecutor to process images in parallel with 4 threads\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:  # Adjust the number of workers as needed\n",
    "        futures = []  # List to store future tasks\n",
    "        # Iterate through each subfolder in the specified folder\n",
    "        for subfolder in tqdm(os.listdir(folder_path)):\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)  # Full path of the subfolder\n",
    "            if os.path.isdir(subfolder_path):  # Check if it's a directory\n",
    "                # Iterate through each file in the subfolder\n",
    "                for file_name in os.listdir(subfolder_path):\n",
    "                    # Process only DICOM files (.dcm)\n",
    "                    if file_name.lower().endswith('.dcm'):\n",
    "                        dicom_path = os.path.join(subfolder_path, file_name)  # Full path of the DICOM file\n",
    "                        png_path = os.path.join(subfolder_path, file_name.replace('.dcm', '.png'))  # Path for the PNG file\n",
    "                        # Submit the process_image task to the thread pool\n",
    "                        futures.append(executor.submit(process_image, dicom_path, png_path))\n",
    "        # Wait for all the tasks to complete\n",
    "        for future in tqdm(futures):\n",
    "            try:\n",
    "                future.result()  # Retrieve the result of each task\n",
    "            except Exception as e:\n",
    "                # Print error message if any task fails\n",
    "                print(f\"Error in processing a future: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the folder containing the DICOM files\n",
    "    folder_path = r\"C:\\Users\\zafer\\Desktop\\competition_dataset\\competition_dataset\"\n",
    "    # Process the DICOM files in the folder\n",
    "    process_images_in_folder(folder_path)\n",
    "    # Print a message once processing is complete\n",
    "    print(\"Image processing complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to read labels from a text file\n",
    "def etiketleri_okumak(txt_konumu):\n",
    "    labels = []\n",
    "    # Open the label file in read mode\n",
    "    with open(txt_konumu, 'r') as file:\n",
    "        # Read each line from the file\n",
    "        for line in file:\n",
    "            # Convert the line into a list of floating-point numbers\n",
    "            numbers = list(map(float, line.split()))\n",
    "            # Append the list of numbers (labels) to the labels list\n",
    "            labels.append(numbers)\n",
    "    # Return the list of labels\n",
    "    return labels\n",
    "\n",
    "# Function to convert compressed labels to actual coordinates for bounding boxes\n",
    "def Sikistirilmis_etiketleri_acmak(sikistirilmis_etiketler, image):\n",
    "    '''The order: x1, x2, y1, y2'''\n",
    "    etiketler = []\n",
    "    # Loop through each label (class, x, y, width, height) from compressed labels\n",
    "    for label in sikistirilmis_etiketler:\n",
    "        # Unpack label components\n",
    "        sinif, x_zip, y_zip, genislik_bbox_zip, yukseklik_bbox_zip = label\n",
    "\n",
    "        # Get image dimensions\n",
    "        img_height, img_width, rgb = image.shape\n",
    "        \n",
    "        # Convert normalized coordinates back to pixel values\n",
    "        x = x_zip * img_width\n",
    "        y = y_zip * img_height\n",
    "        bbox_genislik = genislik_bbox_zip * img_width\n",
    "        bbox_yukseklik = yukseklik_bbox_zip * img_height\n",
    "\n",
    "        # Calculate the top-left (x1, y1) and bottom-right (x2, y2) corner coordinates of the bounding box\n",
    "        x1 = int(x - bbox_genislik / 2)\n",
    "        x2 = int(x + bbox_genislik / 2)\n",
    "        y1 = int(y - bbox_yukseklik / 2)\n",
    "        y2 = int(y + bbox_yukseklik / 2)\n",
    "        \n",
    "        # Append the bounding box coordinates to the etiketler list\n",
    "        etiketler.append([x1, x2, y1, y2])\n",
    "    # Return bounding box coordinates\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "# Function to make predictions using the model\n",
    "def Predict_frame(frame, model):\n",
    "    # Use the model to make predictions on the frame\n",
    "    predictions = model(frame, save_txt=None)\n",
    "    labels = []\n",
    "    \n",
    "    # Loop through each prediction (bounding box in xywhn format)\n",
    "    for idx, prediction in enumerate(predictions[0].boxes.xywhn):\n",
    "        # Get the class of the object detected\n",
    "        cls = int(predictions[0].boxes.cls[idx].item())\n",
    "        \n",
    "        # Format the label as \"class x y width height\"\n",
    "        line = f\"{cls} {prediction[0].item()} {prediction[1].item()} {prediction[2].item()} {prediction[3].item()}\"\n",
    "        \n",
    "        # Convert the string to a list of floating-point numbers\n",
    "        numbers = list(map(float, line.split()))\n",
    "        \n",
    "        # Append the numbers to the labels list\n",
    "        labels.append(numbers)\n",
    "        \n",
    "        # Return the labels (since the return statement is inside the loop, it will return after the first prediction)\n",
    "        return labels\n",
    "\n",
    "# Import necessary libraries for image processing and multithreading\n",
    "import os\n",
    "import cv2\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Function to process an image (crop, resize, and save)\n",
    "def process_image(image_path):\n",
    "    try:\n",
    "        # Read the original image\n",
    "        orginal_image = cv2.imread(image_path)\n",
    "        # Read the image again for processing (in case further operations modify it)\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        # Resize the image to 640x640 for prediction\n",
    "        resized = cv2.resize(image, (640, 640))\n",
    "        \n",
    "        # Predict the labels using the model (e.g., object detection)\n",
    "        labels = Predict_frame(frame=resized, model=MemeModeli)\n",
    "        \n",
    "        # Get the actual coordinates for cropping from compressed labels\n",
    "        x1, x2, y1, y2 = Sikistirilmis_etiketleri_acmak(image=image, sikistirilmis_etiketler=labels)\n",
    "        \n",
    "        # Crop the original image based on the bounding box coordinates\n",
    "        cropped_image = orginal_image[y1:y2, x1:x2]\n",
    "        \n",
    "        # Resize the cropped image to 512x512\n",
    "        resized = cv2.resize(cropped_image, (512, 512))\n",
    "        \n",
    "        # Replace the original image with the cropped and resized image\n",
    "        cv2.imwrite(image_path, resized)\n",
    "\n",
    "        # Return the path of the processed image\n",
    "        return image_path\n",
    "    \n",
    "    except AttributeError as e:\n",
    "        # Print error if there is an attribute-related issue\n",
    "        print(f\"AttributeError encountered for {image_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Print general error if image processing fails\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process all images in the root folder\n",
    "def process_images_in_root_folder(root_folder):\n",
    "    # Get a list of subfolders within the root folder\n",
    "    subfolders = [f for f in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, f))]\n",
    "    total_subfolders = len(subfolders)\n",
    "    \n",
    "    # Process each subfolder one by one\n",
    "    for i, subfolder in enumerate(subfolders, 1):\n",
    "        print(f\"Processing subfolder {i}/{total_subfolders}: {subfolder}\")\n",
    "        \n",
    "        # Get the full path of the subfolder\n",
    "        subfolder_path = os.path.join(root_folder, subfolder)\n",
    "        \n",
    "        # Get the full paths of all images within the subfolder\n",
    "        image_paths = [os.path.join(subfolder_path, image_name) for image_name in os.listdir(subfolder_path)]\n",
    "        \n",
    "        # Use multithreading to process images in parallel\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            # Submit each image processing task to the thread pool\n",
    "            futures = {executor.submit(process_image, image_path): image_path for image_path in image_paths}\n",
    "            \n",
    "            # Track the progress of each image processing task\n",
    "            for future in as_completed(futures):\n",
    "                # Get the path of the processed image\n",
    "                processed_image_path = future.result()\n",
    "                if processed_image_path is not None:\n",
    "                    # Print message indicating successful processing\n",
    "                    print(f\"Processed {processed_image_path}\")\n",
    "\n",
    "# Set the root folder path where images are stored\n",
    "root_folder = r'C:\\Users\\zafer\\Desktop\\Biradscompetition_dataset\\competition_dataset'\n",
    "\n",
    "# Process all images within the root folder\n",
    "process_images_in_root_folder(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Define the paths\n",
    "model_path = r\"C:\\Users\\zafer\\Desktop\\biradsyoloWeight\\best.pt\"\n",
    "images_directory = r\"C:\\Users\\zafer\\Desktop\\Biradscompetition_dataset\\competition_dataset\"\n",
    "output_csv = r\"C:\\Users\\zafer\\Desktop\\biradSimage_predictions.csv\"\n",
    "\n",
    "# Load your model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# List to hold the results\n",
    "results_list = []\n",
    "\n",
    "# Iterate over all images in the directory\n",
    "for filename in os.listdir(images_directory):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Check for image files\n",
    "        image_path = os.path.join(images_directory, filename)\n",
    "\n",
    "        try:\n",
    "            # Run prediction\n",
    "            results = model(image_path)\n",
    "\n",
    "            # Extract the top-1 class name\n",
    "            top1_index = results[0].probs.top1  # Get the top-1 predicted class index\n",
    "            class_name = results[0].names[top1_index]  # Convert index to class name\n",
    "\n",
    "            # Append the results to the list\n",
    "            results_list.append({\n",
    "                'filename': filename,\n",
    "                'kategori': class_name\n",
    "            })\n",
    "\n",
    "            print(f\"Image: {filename}, Detected class: {class_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "df = pd.DataFrame(results_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Results saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
